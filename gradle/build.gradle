import groovy.json.*
import java.util.concurrent.Executors
import java.util.concurrent.TimeUnit

plugins {
  id "de.undercouch.download" version "3.4.3"
}

def slurper = new JsonSlurper()

def ensure_property(def obj, String keyname, List candidates, Integer default_value_index = 0)
{
  if(!obj.hasProperty(keyname)) {
    obj.metaClass.setProperty(keyname, candidates[default_value_index])
  }

  assert(candidates.contains(obj.getProperty(keyname)))
}

// Property about build configuration
ensure_property(project, "config", ["Debug", "Release"])
// Property about ccache.
// (note: ccache is not used if not installed even if this property is true.)
ensure_property(project, "use_ccache", ["true", "false"])
// build libraries even if cache archives are available.
ensure_property(project, "renew_cache", ["false", "true"])
ensure_property(project, "msvc_version", ["Visual Studio 16 2019", "Visual Studio 15 2017"])

ensure_property(project, "cache_strategy", ["azure", "file", "null"])

// enable setting cache title to distiguish stored caches with titles.
if(project.hasProperty("cache_title") == false) {
  project.metaClass.setProperty("cache_title", "")
}

project.cache_title = project.cache_title.trim().replaceAll(/ /, "_")

ext {
  isWindows = { return System.properties['os.name'].toLowerCase().startsWith("windows") }
  build_dir_name = "build"
  should_renew_cache = (project.renew_cache == "true")
  getCMakeGenerator = {
    return isWindows() ? "-G \"${project.msvc_version}\" -A x64" : "-G Xcode"
  }
  isGnuTar = {
    return ("tar --version".execute().text.trim() ==~ /.*bsdtar.*/) == false
  }
}

//! @param options is a map to customize getenv behavior.
//! these options are supported.
//! * null_as_empty. (Boolean, default is false)
//! * trim. (Boolean. default is false)
def getenv = { String key, Map options = [:] ->
  def tmp = java.lang.System.getenv()[key]
  if(options["null_as_empty"]) {
    if(tmp == null) { tmp = "" }
  }

  if(options["trim"]) {
    tmp = tmp.trim()
  }
}

// 渡された文字列を空白で区切って、単語のリストとして返す。
// ただし、引用符(`'` or `"`)で囲まれた範囲は空白で区切らずに、ひと続きの文字列とみなす
// 引用符で囲まれた範囲内であっても、`\"`のようにエスケープされているものや、
// 引用符の種類が異なるものは引用符の終わりとはみなさない。
// ex) tokenize(/abc def "ghi \"jkl ' mno" pqr/) => [abc, def, "ghi \"jkl ' mno", pqr]
// @return [
//    tokens: <tokenized string list if succeeded, [] otherwise>,
//    error: <error msg if something failed, "" otherwise.>
// ]
def tokenize_with_error(String src)
{
  logger.info("start tokenize: ${src}")

  def separator_char = ' '
  def escape_char = '\\'
  def quote_chars = [/'/, /"/]

  String token = ""
  def output = []
  def is_escaped = false
  def found_quote = ""
  def quoted = { found_quote != "" }

  src.each { it ->
    logger.debug("it: ${it}")

    if(quoted()) {
      if(is_escaped) {
        is_escaped = false
        logger.debug("\t--1")
      } else if(it == escape_char) {
        is_escaped = true
        logger.debug("\t--2")
      } else if(it == found_quote) {
        found_quote = ""
        logger.debug("\t--3")
        return
      }
    } else {
      if(quote_chars.contains(it)) {
        found_quote = it
        logger.debug("\t--4")
        return
      } else if(it == separator_char) {
        if(token != "") {
          logger.debug("\t--5")
          output << token
          token = ""
        }
        return
      }
    }

    token += it
  }

  if(quoted()) {
    return [ tokens: [], error: "quotation is not closed." ]
  }

  if(token != "") { output << token }
  return [ tokens: output, error: "" ]
}

def tokenize(String str)
{
  def result = tokenize_with_error(str)
  assert(result.error == "")
  return result.tokens
}

task test_tokenize {
  def is_failed = false
  def fail = { String msg ->
    logging.error(msg)
    is_failed = true
  }
  def test = { String str, List expected ->
    def result = tokenize_with_error(str)
    if(result.tokens != expected) {
      fail("given:[${str}], expected:${expected}, but:" + result.tokens)
    }
  }
  doLast {
    test("", [])
    test("abc", ["abc"])
    test(/"abc"/, [/"abc"/])
    test('abc def', ["abc", "def"])
    test("abc'def", [])            // error: /'/ is not closed.
    test('abc"def', [])            // error: /"/ is not closed.
    test($/abc"def\"/$, [])        // error: /"/ is not closed because escaped.
    test("abc'def'", ["abc'def'"])
    test("abc 'def ghi'", ["abc", "'def ghi'"])
    test("abc'def ghi'", ["abc'def ghi'"])
    test($/abc 'def" ghi'/$, ["abc", $/'def" ghi'/$]) // /"/ can be placed and no need to be closed in /'/ pair
    test($/abc "def\" 'ghi jkl'"/$, ["abc", $/"def\" 'ghi jkl'"/$])

    if(is_failed) { assert false, "[FAILED]" } else { println "[PASS]" }
  }

  description = """test tokenize() function"""
}

class ExecutionResult
{
  def ExecutionResult(int exit_value, String text, String error_text)
  {
    this.exit_value = exit_value
    this.text = text
    this.error_text = error_text
  }

  int exitValue() { return exit_value }
  boolean succeeded() { return exit_value == 0 }
  boolean failed() { return exit_value != 0 }

  String getText() { return text }
  String getErrorText() { return error_text }

  int exit_value
  String text
  String error_text
}

//! execute specified command and wait for finish the execution.
//! @param command is a string consists of executable command and its parameters.
//! @param working_dir is the working directory for the executable.
//! @param env_vars is environment variables as a list of key:value pair. this parameter may be nil.
def execute_may_fail = { String command, def working_dir = ".", Map env_vars = [:] ->
  if(isWindows()) {
    command = "cmd /c chcp 65001 > nul & " + command.toString()
  }

  def tmp = tokenize(command)
  println "${tmp} @ '${working_dir}' (${env_vars})"

  def pb = new ProcessBuilder(tokenize(command))
  pb.directory(file(working_dir).getAbsoluteFile())

  if(env_vars) {
    def pb_env = pb.environment()
    env_vars.each { key, value -> pb_env.put(key, value) }
  }

  def process = pb.start()
  String text = ""
  String error_text = ""

  def service = Executors.newCachedThreadPool()

  service.execute {
    process.in.eachLine { line ->
      text += line + "\n"
      System.out.&println line
    }
  }

  service.execute {
    process.err.eachLine { line ->
      error_text += line + "\n"
      System.err.&println line
    }
  }

  process.waitFor()

  service.shutdown()
  service.awaitTermination(1, TimeUnit.MINUTES)

  return new ExecutionResult(process.exitValue(), text, error_text)
}

//! similar to execute_may_fail but this function fails if the command finished with an exit value of non zero.
def execute = { String params, def working_dir = ".", Map env_vars = [:] ->
  def result = execute_may_fail(params, working_dir, env_vars)
  assert (result.exitValue() == 0), "undesirable exit value ${result.exitValue()}"
  return result
}

// 指定したディレクトリが存在しなければ作成し、成功か失敗かをbooleanで返す
// 存在する場合は何もせずにtrueを返す
def mkdirs_if_needed = { def path ->
  def f = file(path)
  if(f.exists()) { return true }

  return f.mkdirs()
}

def createCacheParam = { File cache_dir, String archive_name, String build_config, String hash ->
  def getOsName = { return isWindows() ? "win" : "mac" }
  return [
    getOsName: getOsName,
    cache_dir: cache_dir,
    archive_name: archive_name,
    build_config: build_config,
    hash: hash,
    getArchiveFileName: {
      def name = project.cache_title
      if(name != "") { name += "_" }
      name += "${archive_name}_${getOsName()}_${build_config}_${hash}.tar.gz"
      assert(name.contains(" ") == false)
      return name
    }
  ]
}

// interface CacheStrategy
// {
//   boolean fetch(def param)
//   boolean store(def param)
// }

def createNullCacheStrategy = {
  return [
    fetch: { def param -> return false },
    store: { def param -> return false },
  ]
}

def createFileCacheStrategy = {
  def cache_dir = file("/opt/terra_cache")

  def isCached = { def param ->
    return file("${cache_dir}/${param.getArchiveFileName()}").exists()
  }

  return [
    fetch: { def param ->
      if(isCached(param) == false) {
        return false
      }

      if(mkdirs_if_needed(param.cache_dir) == false) {
        assert false, "failed to create ${param.cache_dir}"
      }

      execute("cmake -E copy ${cache_dir}/${param.getArchiveFileName()} ./", param.cache_dir)

      // extract archive
      def result = execute_may_fail(
        "tar ${isGnuTar() ? "--force-local" : ""} -xvf ${param.getArchiveFileName()}"
        , param.cache_dir)

      // remove downloaded archive
      execute("rm '${param.getArchiveFileName()}'", param.cache_dir)

      if(result.failed()) {
        logger.warn("failed extract ${param.getArchiveFileName()}")
        return false
      }

      return true
    },
    store: { def param ->
      assert(file(param.cache_dir).exists())

      if(isWindows()) {
        def tar_result = execute_may_fail(
            "tar ${isGnuTar() ? "--warning=no-file-changed" : ""} --exclude=${param.getArchiveFileName()} -czvhf ${param.getArchiveFileName()} ."
            , param.cache_dir)

        if(tar_result.exitValue() >= 2) {
          logger.warn("failed to create archive.")
          return false
        }
      } else {
        execute("tar -czvhf ${param.getArchiveFileName()} --exclude=${param.getArchiveFileName()} .", param.cache_dir)
      }

      execute("cmake -E copy ${param.getArchiveFileName()} ${cache_dir}/", param.cache_dir)
      execute("rm '${param.getArchiveFileName()}'", param.cache_dir)

      return true
    },
  ]
}

def createAzureCacheStrategy = {
  logger.info("create AzureCacheStrategy object")
  def getAzureStorageAccount = {
    return getenv("AZURE_STORAGE_ACCOUNT", [null_as_empty: true, trim: true])
  }

  def getAzureStorageKey = {
    return getenv("AZURE_STORAGE_KEY", [null_as_empty: true, trim: true])
  }

  def getAzureStorageContainerName = {
    return getenv("AZURE_STORAGE_CONTAINER_NAME", [null_as_empty: true, trim: true])
  }

  def getBlobApiParams = {
    return  " --container-name ${getAzureStorageContainerName()} "
    +       " --storage-account ${getAzureStorageAccount()} "
    +       " --storage-key ${getAzureStorageKey()} "
  }

  def isCached = { def param ->
    def result = execute_may_fail(
      " az storage blob exists ${getBlobApiParams()} "
      + " --name ${param.getArchiveFileName()} "
      )

    if(result.failed()) {
      logger.warn("failed to check the blob existence")
      return false
    }

    def blob_exists_result = slurper.parseText(result.text)
    assert blob_exists_result

    if(blob_exists_result.exists == false) {
      return false
    }
  }

  if(isWindows()) {
    if(execute_may_fail("where az").failed()) {
      logger.info("az command not found")
      return null
    }
  } else {
    if(execute_may_fail("which az").failed()) {
      logger.info("az command not found")
      return null
    }
  }

  if(getAzureStorageAccount() == ""
     || getAzureStorageKey() == ""
     || getAzureStorageContainerName() == "")
   {
      logger.info("azure settings not found")
      return null
   }

  return [
    fetch: { def param ->
      if(isCached(param) == false) {
        return false
      }

      if(mkdirs_if_needed(param.cache_dir) == false) {
        assert false, "failed to create ${param.cache_dir}"
      }

      def result = execute_may_fail(
        " az storage blob download ${getBlobApiParams()} "
        + " --name ${param.getArchiveFileName()} "
        + " --file ${param.getArchiveFileName()} "
        , param.cache_dir)

      if(result.failed()) {
        logger.warn("failed to download the blob")
        return false
      }

      // extract archive
      result = execute_may_fail(
        "tar ${isGnuTar() ? "--force-local" : ""} -xvf ${param.getArchiveFileName()}"
        , param.cache_dir)

      // remove downloaded archive
      execute("rm '${param.getArchiveFileName()}'", param.cache_dir)

      if(result.failed()) {
        logger.warn("failed extract ${param.getArchiveFileName()}")
        return false
      }

      return true
    },
    store: { def param ->
      assert(file(param.cache_dir).exists())

      if(isWindows()) {
        def tar_result = execute_may_fail(
            "tar ${isGnuTar() ? "--warning=no-file-changed" : ""} --exclude=${param.getArchiveFileName()} -czvhf ${param.getArchiveFileName()} ."
            , param.cache_dir)

        if(tar_result.exitValue() >= 2) {
          logger.warn("failed to create archive.")
          return false
        }
      } else {
        execute("tar -czvhf ${param.getArchiveFileName()} --exclude=${param.getArchiveFileName()} .", param.cache_dir)
      }

      def result = execute_may_fail(
        " az storage blob upload "
        + " ${getBlobApiParams()} "
        + " --name ${param.getArchiveFileName()} "
        + " --file ${param.getArchiveFileName()} "
        , param.cache_dir)

      execute("rm '${param.getArchiveFileName()}'", param.cache_dir)

      if(result.failed()) {
        logger.warn("failed to upload cache")
        return false
      }

      return true
    },
  ]
}

def get_hash = { String submodule_name ->
  def result = execute("git rev-parse HEAD", file("../ext/${submodule_name}"))
  return result.text.trim()
}

def get_cache_strategy = {
  if(project.cache_strategy == "azure") {
    return createAzureCacheStrategy()
  } else if(project.cache_strategy == "file") {
    return createFileCacheStrategy()
  } else {
    return createNullCacheStrategy()
  }
}

// 指定したディレクトリのキャッシュが有効なときはそれを使用し、
// キャッシュがないときはビルドを行う
def build_if_needed = { String archive_name, File cache_dir, String hash, Closure do_build ->
  def cache = get_cache_strategy()
  assert(cache)

  def param = createCacheParam(cache_dir, archive_name, project.config, hash)

  if(should_renew_cache) {
    println "Renew cache"
  } else {
    // fetchしたデータの正当性は確認しない
    // （正当性を確認して、内容が不十分なときはdo_buildでビルドし直すような設計も考えられるが、
    // do_buildの実装側が面倒になるので、そこまではしない）
    def fetched = cache.fetch(param)
    if(fetched) { return }
  }

  do_build()
  def result = cache.store(param)
  if(result == false) {
    logger.warn("Failed to store cache")
  }
}

task update_submodules {
  doLast {
    execute("git submodule sync", file(".."))
    execute("git submodule update --init --recursive", file(".."))
  }
}

task prepare_project {
  mustRunAfter update_submodules
  doLast {
    def build_dir = file("../build").getAbsolutePath()
    assert(mkdirs_if_needed(build_dir))
    execute("cmake ${getCMakeGenerator()} ..", build_dir)
  }
}

task compile_schemas {
  compile_schemas.mustRunAfter prepare_project
  doLast {
    def protoc = file("../build/install/${project.config}/opt/protobuf/bin/protoc${isWindows() ? '.exe' : ''}").getAbsolutePath()
    assert(file(protoc).exists())

    assert(mkdirs_if_needed(file("../schema/cpp")))
    file("../schema").eachFileMatch(~/.*\.proto$/) {
      execute("'${protoc}' -Ischema --cpp_out=schema/cpp '${it.getName()}'", "..")
    }
  }
}

task copy_resources {
  doLast {
    // there is no need to copy resources with this task on macOS,
    // because the resources are copied into a bundle directory by cmake script.
    if(isWindows() == false) { return; }

    def output_dir = file("../build/${project.config}").getAbsolutePath()

    def src = file("../data")
    def dest = new File(output_dir, "Resource")
    assert(mkdirs_if_needed(output_dir))
    copy {
      from src
      into dest
    }
  }

  description = """copy resource data into the output directory."""
}

ext {
  buildProject = { String target_name ->
    def build_dir = file("../${build_dir_name}").getAbsolutePath()
    // for macOS, Xcode build performs parallel builds by default and
    // requires a number of concurrency for this option.
    def parallel_option = isWindows() ? "-j" : ""
    execute("cmake --build . ${parallel_option} --target ${target_name} --config ${project.config}", build_dir)
  }
}

task build_target {
  dependsOn { [copy_resources, update_submodules, prepare_project] }
  doLast {
    assert(project.hasProperty("target"))
    buildProject(project.target)
  }
}

def submodule_target_list = ["protobuf", "wxWidgets", "portaudio", "fmt", "vst3sdk"]

submodule_target_list.each { def name ->
  task "build_${name}" {
    dependsOn { [copy_resources, update_submodules, prepare_project] }
    doLast {
      build_if_needed(name, file("../build/src/${name}-build"), get_hash(name), {
        buildProject(name)
      })
    }
  }
}

task build_submodules {
  def deps = [copy_resources, update_submodules, prepare_project]

  submodule_target_list.each { def name ->
    deps << "build_${name}"
  }

  dependsOn { deps }
}

task build_app {
  dependsOn { [copy_resources, update_submodules, prepare_project] }
  mustRunAfter build_submodules
  doLast {
    buildProject("Terra")
  }
}

task build_test {
  dependsOn { [copy_resources, update_submodules, prepare_project] }
  mustRunAfter build_submodules
  doLast {
    buildProject("Terra-Test")
  }
}

task run_test {
  mustRunAfter build_test
  doLast {
    assert(project.config == "Debug")

    def build_dir = file("../build/Debug").getAbsolutePath()
    if(isWindows()) {
      execute("Terra-Test.exe", build_dir)
    } else {
      execute("Terra-Test.app/Contents/MacOS/Terra-Test", build_dir)
    }
  }
}

task test {
  dependsOn { [build_test, run_test] }
}

task build_all {
  dependsOn { [test, build_app] }
}

gradle.taskGraph.whenReady {taskGraph ->
  if(taskGraph.hasTask(build_target)) {
    assert project.hasProperty("target")
  }
}

defaultTasks "build_all"

